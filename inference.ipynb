{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mmmfr\\Documents\\Repositories\\minecraft-schematic-generator\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from converter import SchematicArrayConverter\n",
    "from modules import LightningTransformerMinecraftStructureGenerator\n",
    "\n",
    "model_version = 89\n",
    "output_dir = 'schematic_viewer/public/schematics/'\n",
    "checkpoint_path = f'lightning_logs/minecraft_structure_generator/version_{model_version}/checkpoints/last.ckpt'\n",
    "# checkpoint_path = f'lightning_logs/version_{model_version}/checkpoints/last.ckpt'\n",
    "model = LightningTransformerMinecraftStructureGenerator.load_from_checkpoint(\n",
    "    checkpoint_path)\n",
    "model.eval()\n",
    "\n",
    "converter = SchematicArrayConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing inference...\n",
      "Converting output array to schematic...\n",
      "Saving schematic to file...\n",
      "Performing inference...\n",
      "Converting output array to schematic...\n",
      "Saving schematic to file...\n"
     ]
    }
   ],
   "source": [
    "# Loop to take user input and perform inference\n",
    "while True:\n",
    "    prompt = input(\"Enter your text input (or type 'exit' to stop): \")\n",
    "    if prompt.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        print(\"Performing inference...\")\n",
    "        output = model.generate(prompt, 1.0)\n",
    "        # output = model.generate(prompt, 0.7)\n",
    "        output = output.cpu().numpy()\n",
    "\n",
    "    print(\"Converting output array to schematic...\")\n",
    "    schematic = converter.array_to_schematic(output)\n",
    "    schematic.name = prompt\n",
    "    print(\"Saving schematic to file...\")\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    unique_filename = f'inference_{timestamp}.schem'\n",
    "    path = Path(output_dir) / unique_filename\n",
    "    schematic.save_to_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting temperature to 0.25\n",
      "Performing inference...\n",
      "Converting output array to schematic...\n",
      "Saving schematic to file...\n",
      "Setting temperature to 0.5\n",
      "Performing inference...\n",
      "Converting output array to schematic...\n",
      "Saving schematic to file...\n",
      "Setting temperature to 1.0\n",
      "Performing inference...\n",
      "Converting output array to schematic...\n",
      "Saving schematic to file...\n",
      "Setting temperature to 2.0\n",
      "Performing inference...\n",
      "Converting output array to schematic...\n",
      "Saving schematic to file...\n",
      "Setting temperature to 4.0\n",
      "Performing inference...\n",
      "Converting output array to schematic...\n",
      "Saving schematic to file...\n"
     ]
    }
   ],
   "source": [
    "# Loop to take user input and perform inference\n",
    "while True:\n",
    "    prompt = input(\"Enter your text input (or type 'exit' to stop): \")\n",
    "    if prompt.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    temperature = 0.25\n",
    "    for i in range(5):\n",
    "        print(f\"Setting temperature to {temperature}\")\n",
    "\n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            print(\"Performing inference...\")\n",
    "            output = model.generate(prompt, temperature)\n",
    "            output = output.cpu().numpy()\n",
    "\n",
    "        print(\"Converting output array to schematic...\")\n",
    "        schematic = converter.array_to_schematic(output)\n",
    "        schematic.name = prompt\n",
    "        print(\"Saving schematic to file...\")\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        unique_filename = f'inference_{timestamp}.schem'\n",
    "        path = Path(output_dir) / unique_filename\n",
    "        schematic.save_to_file(path)\n",
    "\n",
    "        temperature *= 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
