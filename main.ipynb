{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples: 100%|██████████| 100/100 [00:52<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing old sample 028e2f89f09178d38d14c8cd5f2b65e2ce9be704f70f6581289744eeed4ee2b2.schem\n",
      "Removing old sample 0815de319f29f61d04044cecf1f7c7e60ebc7fd9518e6bcc0013086d920e9d8a.schem\n",
      "Removing old sample 091f4e6e777a4f1d12b56206166ba6aeab17a906d2c95c950c1e9af8110f398b.schem\n",
      "Removing old sample 0d05443b087b559f07a4bcb131240b4e9c5d531e7968a16d62fe4bc3a11fba74.schem\n",
      "Removing old sample 0f6e2c72aa6cfb63ede42b9a41a41c7c5553ce20c3bd360d5d561dfbc1291903.schem\n",
      "Removing old sample 101da1980ebbed3f9ba619ea9dfa7f5b56e9178bfa665d28499a0b3c53b31ef0.schem\n",
      "Removing old sample 12e3ca439d34d16277cfe612b27e170c7d08b2480d694031ccf551912d2be228.schem\n",
      "Removing old sample 1455d2bbb71654795f8984f569d64df927fdf907c6b7a2f9f00286a835d57019.schem\n",
      "Removing old sample 1d0b6ca3e75d089210edaad2d8ba25d2aae860ed70a47d02a4b367f931449192.schem\n",
      "Removing old sample 1d1c98e14f36caa1bd05515d9637b239c0056cf06c5efea70ceeda1d09c50082.schem\n",
      "Removing old sample 1d779bea9ca4f526aed1f3d71b2f5226e5917a75d8a8376c9e8d01ddf5c0a0cb.schem\n",
      "Removing old sample 210345f2b52eaa966c360b56f4cf070267149e18d527e59e92dca6afd3507ea7.schem\n",
      "Removing old sample 2176fad365a6f19b817c79db1b784f0d9a175b950c00a18e7620ef5de7c7bc06.schem\n",
      "Removing old sample 21e79276b4ae4b58fa40103eff5b9b1641a15a4633837dbff63a74abbd2fd6d9.schem\n",
      "Removing old sample 2269c79ce2a34a9f8597967717600f158c42b700b94bd790784f8ef11b4cf069.schem\n",
      "Removing old sample 227b2e13ff8534262d651ff1b812d52923f1ad5b30526ff2c134ec49931dd123.schem\n",
      "Removing old sample 23701d1783e72da60d03bdf97e034894e83d7a91289d7d0e1e8726d8f7c0e1a8.schem\n",
      "Removing old sample 289d014d0e21d38c5d751911027b6a24e73007c407c63f573bdf5294251349b7.schem\n",
      "Removing old sample 2f63257716fafa6b88c58335286e4286d940457dbb69b12ce80b2752a9749bd8.schem\n",
      "Removing old sample 2fd93926a98b9d984fa2082457160e881dc5aff6ef2f53e99ba32fa27052fc0a.schem\n",
      "Removing old sample 34340151f2a19407e2a48c6a4c1ce7dc5ab69f1f822549f460dbb5def84cbd23.schem\n",
      "Removing old sample 36ce32f92644778d5067cd3412b4c03da63f415d2efe31487452d15a8d118fe8.schem\n",
      "Removing old sample 39a4bcb11f93b57bb9381c7dc5c6bddf5a02d925311ac08c8acfafd2910d37cb.schem\n",
      "Removing old sample 3c53c2adf9b73f25fffdde2ab1ec3b52efdd68c72f744651f1b989464b147485.schem\n",
      "Removing old sample 3c85dfb1c3132729b59c75c0a95624ed8f4e664e799a0923d4f3166fcc767431.schem\n",
      "Removing old sample 3decd71c97187daf7486647ed7b53e57238ee71812cd878b691407951757b6ea.schem\n",
      "Removing old sample 3e0129dd1a50529b5742b5ef144eccd48bb596554caa7ee1e1436fd77e589356.schem\n",
      "Removing old sample 3fc6c4bbd8bd5e54740d2cd2d0dc17d8a36f22c40e0d059f07306afba6e97f35.schem\n",
      "Removing old sample 44283c017fbd9419d509fcafa4f2adeb4b3c8112e88f2fa4da10a7ba8ce09ed7.schem\n",
      "Removing old sample 492cde61cc8733681a5536a107e044c0543d66a97315f0e687aa6b64f6cb6c6d.schem\n",
      "Removing old sample 49a72608dee6ee88d508f835a4ca0932f5c9a0fd97836146d61e122dbff9b687.schem\n",
      "Removing old sample 4a89cb6710a776a39212a86651bcbf56654e88f50fbe5f6097498c959a77f853.schem\n",
      "Removing old sample 4bf0373c03ca91db4f3c9cb36a2bd99411bb0a81e7d1b435cc6a895a1f82894d.schem\n",
      "Removing old sample 4d8e3ec44b0536b3fc29d326036aa1964f8a40f5d50d377820fa339fbc1f6043.schem\n",
      "Removing old sample 4fd09f56b74d942bd96dd791dbf4d63b29f5777125d47950198d7261b3d237d2.schem\n",
      "Removing old sample 54354d057d01936c45874d59ad7208e3202c638d96b22f8661afa75dac6f2ca8.schem\n",
      "Removing old sample 56def6fa127ba5e6942189ea8cfe31ebd823629ec865c871abfbad17484e84d6.schem\n",
      "Removing old sample 57feaf9acbf2dff0f1e66ffc9453914fbb1b5098b9eda7bd956f316430b5d071.schem\n",
      "Removing old sample 5f8c596c7998038a79c0369a2fe661c285a7860f1cfb17b5aabf8040872df0ff.schem\n",
      "Removing old sample 61aaa1241ce62a5ed7b0289c3c671b3c04be07ba27e48e706d57f594ff9f1e0b.schem\n",
      "Removing old sample 679c915cfe38f991143d922c75356ddeebec8459592848b8aec36c090acea0e0.schem\n",
      "Removing old sample 68b29e22b68123a660292fc6c093a7ff701b4336645b522addbb0ea5bfb6027f.schem\n",
      "Removing old sample 69b14e79d605903147760dd41b9adc110d37655acbfb8d90ffd4f7f78784e780.schem\n",
      "Removing old sample 6b3c6d3757412f65f740aefdef57d00174d8882d8e198b3e20687900c4736526.schem\n",
      "Removing old sample 6bacdd8bdad7554fa930501df10ba692638a82e6418a458945ca7e3d20476dba.schem\n",
      "Removing old sample 6c1dc65ccac540f964a9653fb4a04184e326343f2348277955a95e8b87123bd5.schem\n",
      "Removing old sample 6c543cb91813254ba5b427cd5413a647876132b3e8710259ce9e07a7d2a0cd3c.schem\n",
      "Removing old sample 6f386c7f48c7a0ba17d94638fbbd382d50437638539457f6dad15a3ddcbf6738.schem\n",
      "Removing old sample 7061008e04c6aae251be635789f2e8ac33f487b006d4c50722200b65ce0c0658.schem\n",
      "Removing old sample 727ea6ec174519b654446d11f8057365cb6704be199970573cbed8638315d57d.schem\n",
      "Removing old sample 79077710c7aa16b53fbe77724a612fa7e71a2069faf8cfdfed8babc441908d40.schem\n",
      "Removing old sample 7b6f4ddd8a353cc29ea81493da92f295c7368ed1d6bf98f9f74a3c165e19d22a.schem\n",
      "Removing old sample 8571110475a52e00ac7b832aa39b9bfdabc36c6d912cafd1f66cbfd433b25662.schem\n",
      "Removing old sample 87480f73ff57d60e601d28b610340c3a9d8494842d4f926f84d2a440a25309dd.schem\n",
      "Removing old sample 885575c3186e92f23af65b596c3baf7368e24389f1f1262082ead9d031f183af.schem\n",
      "Removing old sample 8be5c1b0336335470cddc0139c25f69c06d2fb34ae926f0160431d7fe276293e.schem\n",
      "Removing old sample 8dc7d3fc527040d56a1b1f580db4db835029ec1b22f00c38aeb68e09196b54eb.schem\n",
      "Removing old sample 8fceff415986afa600d89e90376bfe0ca790f256fcff20acd067bdfef41940bc.schem\n",
      "Removing old sample 9931d9c139743216f135ea2f29b22a83159ca4e2ab11ffcbaece73e28bb0d6ca.schem\n",
      "Removing old sample 9c2138239b1dfd66523b73f78d549ab81fdca6ca476f1f54467b47f185543c11.schem\n",
      "Removing old sample a063b76270a73f1296cfb67f21c549afa064fecc09ee749b483d968ebb1d0125.schem\n",
      "Removing old sample a5e9e7dbab545cf8eb172cba7b8b81c3f4ac496c93f13807d02f21612a533ce4.schem\n",
      "Removing old sample a6637084bbd0428695045d292557a421f4f06ef7f0aad3b183901fca8c207330.schem\n",
      "Removing old sample ab1566d6fbe017a94eec642de180d0a5b5d96728e754e4c6f0a99be887a11d51.schem\n",
      "Removing old sample acc26201143084893d9498753f9cb48769ac071e21d60b4f8a298282f15a6bb9.schem\n",
      "Removing old sample b2900b0acaba5027dacf86168dd00c9cf23636ea1d00914b4f314ac288b68ed4.schem\n",
      "Removing old sample b40227d3a6a246642dcd968019a429564dcfbb5e33cdae99def1913754138a3c.schem\n",
      "Removing old sample b61815a7a74a0cdaeb856aafd0ebc1d3546e9a61d3b5aae71f532e1ac4a1ad94.schem\n",
      "Removing old sample b62d8161c3b2225085f0e47a7981a96cdd96bd7ca0bbdd03b488441d31a3ab87.schem\n",
      "Removing old sample b6ed6b269458ff87bc5c2cf3205b16561f91939c29c836eb39e1dc75e42f14a2.schem\n",
      "Removing old sample b968152589943d141fa149a86ab547ebf87a92222ce23b8f294a3115fe21a76a.schem\n",
      "Removing old sample ba5be7060dfc9a26943747931a29cd63cc72b48d4a7f1d97b513a4fb211c91bb.schem\n",
      "Removing old sample ba89e836e4e93636a6b0a3d5183249b8f8b397732c75bc27bc1227b1bd910719.schem\n",
      "Removing old sample bb11dfebd59922c0d103aa354d73661190fabba466787cc408b67aebcbddfb6f.schem\n",
      "Removing old sample bbbf3d65348aa85054e2c1fd302239410def878923e1a10a9b67dd043adad66c.schem\n",
      "Removing old sample bdc3be0774cf8b8004ac64c0bb0a64a66e129e7e48cb1da25097f9015d1285ea.schem\n",
      "Removing old sample bf3cd4d4e87028beda261465b7795ee5b115bb2c2b79f203d6432ad264ada846.schem\n",
      "Removing old sample c0b4b27484c11f2c2c5fe1b8b5ccad740421ee601812fb9c5c25a2fded0d7527.schem\n",
      "Removing old sample c0c6c27b7b8d99f0f808a8be2da7f520d1ec9c85ba6d2a87eb60e8ae61fdbe76.schem\n",
      "Removing old sample c1103135c681858a0943878e56a1a10cdf802891a58be0a524cc618ff6607e78.schem\n",
      "Removing old sample c20f1848bd42823c900004d993f173ef1a114cf8eaf7f8f023a86984cd5b0fcb.schem\n",
      "Removing old sample c54e8070c25c65078fc0e1117a7f90a8d8ff130fc7e333d03b82e73aaff52872.schem\n",
      "Removing old sample c58974b896697fd6fadc9e708a0941a8d41a76511469e317e0b902073a10cba7.schem\n",
      "Removing old sample c63de19949ae8e849a5f412655ad0e234cd024212c074fa20e184da704cd1e45.schem\n",
      "Removing old sample cc9851c2d814d0c8f5bf7efce27a1911a0fc719eb4667258384b04c4bf0ef24c.schem\n",
      "Removing old sample d5ecf3256f136d24617b254a87413457b5b32d774c16ce80bcb7722f5cb7bc2f.schem\n",
      "Removing old sample d7a79e91329ab603a1b84f48e7d29c88251b1ff1dbfe50583c9b60f6651ed1b4.schem\n",
      "Removing old sample dbc5569d4381d3767a89fb72583ae0613c5a28ebdd33dce6d9e279774028e6e9.schem\n",
      "Removing old sample e12c7897c19e392a135ba8f10b4f49f1b953d965e11fc2004708f969a958442b.schem\n",
      "Removing old sample e2fda8d2beefb124ebd515b936dbd4ae17e799c0fa1c973227b807bc685dbbf1.schem\n",
      "Removing old sample e521be42b382161d845bb61800c7e85fee1cbb3ce397b9634576ad6494ab3211.schem\n",
      "Removing old sample ed52a3a7ef4498bfe2feba33716271b954a030ef66f4f9c91cd3eea6e28425af.schem\n",
      "Removing old sample f1a77b0389c826b139e139f0ab5fea8ae4cd8c2b19649950f648321106f13d55.schem\n",
      "Removing old sample f52319c9f9b96dfa99ed02ee95234709e34389dedd5f0dd18cf7e257b9e726d5.schem\n",
      "Removing old sample f8b0178d1e3ff3dc8e7d123963c71671ff1fe65be338d939929d6c827f3611d3.schem\n",
      "Removing old sample fa72cf335021d605880a70f462d2affb9dcf6e412e29fe71eac28c5c79308e32.schem\n",
      "Removing old sample fb31b750d5250df1e99e3745961993824d1bf6bfe82e830695e53b378889f306.schem\n",
      "Removing old sample fc56cf20ba471db9131502ff98083a70ca67c552fd9cb50f2c0e4c02781e0871.schem\n",
      "Removing old sample fced3a5445e8d94737515d8035651ff1e0e0c0dbf87e1b9a90f4812b1e81c4ac.schem\n",
      "Removing old sample fe0a7521be64b820d00f45f44ba29e0a820ffde02f68a0dbe56977ccb38560f2.schem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from common import constants\n",
    "from schematic_generator import generator\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "configs = [\n",
    "    # Simple shapes\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"sphere\"],\n",
    "        \"radius\": [lambda: random.randint(1, (constants.region_size[0] // 2) - 1)] * 5,\n",
    "        \"structure_block_types\": [[block] for block in constants.simple_block_types] + [lambda: random.sample(constants.simple_block_types, 3)] * len(constants.simple_block_types),\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [lambda: (random.randint(-100, 100), random.randint(-100, 100), random.randint(-100, 100))],\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    },\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"cube\"],\n",
    "        \"side_length\": [lambda: random.randint(1, constants.region_size[0] - 1)] * 5,\n",
    "        \"structure_block_types\": [[block] for block in constants.simple_block_types] + [lambda: random.sample(constants.simple_block_types, 3)] * len(constants.simple_block_types),\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [lambda: (random.randint(-100, 100), random.randint(-100, 100), random.randint(-100, 100))],\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    },\n",
    "    # Filled\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"sphere\"],\n",
    "        \"radius\": [lambda: random.randint(3, (constants.region_size[0] // 2) - 1)] * 3,\n",
    "        \"structure_block_types\": [[block] for block in constants.simple_block_types] + [lambda: random.sample(constants.simple_block_types, 3)] * (len(constants.simple_block_types) // 3),\n",
    "        \"structure_fill_block_types\": [[\"minecraft:air\"], lambda: random.sample(constants.simple_block_types, 1), lambda: random.sample(constants.simple_block_types, 3)],\n",
    "        \"thickness\": [lambda: random.randint(1, 3)],\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [lambda: (random.randint(-100, 100), random.randint(-100, 100), random.randint(-100, 100))],\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    },\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"cube\"],\n",
    "        \"side_length\": [lambda: random.randint(7, constants.region_size[0] - 1)] * 3,\n",
    "        \"structure_block_types\": [[block] for block in constants.simple_block_types] + [lambda: random.sample(constants.simple_block_types, 3)] * (len(constants.simple_block_types) // 3),\n",
    "        \"structure_fill_block_types\": [[\"minecraft:air\"], lambda: random.sample(constants.simple_block_types, 1), lambda: random.sample(constants.simple_block_types, 3)],\n",
    "        \"thickness\": [lambda: random.randint(1, 3)],\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [lambda: (random.randint(-100, 100), random.randint(-100, 100), random.randint(-100, 100))],\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    }\n",
    "]\n",
    "\n",
    "simple_cubes = [\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"cube\"],\n",
    "        \"side_length\": [32],\n",
    "        \"structure_block_types\": [[block] for block in random.sample(constants.simple_block_types, 100)],\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [(0, 0, 0)],\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    }\n",
    "]\n",
    "\n",
    "simple_spheres = [\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"sphere\"],\n",
    "        \"radius\": [8],\n",
    "        \"structure_block_types\": [[block] for block in random.sample(constants.simple_block_types, 50)],\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [(0, 0, 0)],\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    }\n",
    "]\n",
    "\n",
    "# generator.generate_samples_from_configurations(configs, dry_run=False)\n",
    "generator.generate_samples_from_configurations(simple_cubes, 'simple_cubes')\n",
    "# generator.generate_samples_from_configurations(simple_spheres, 'simple_spheres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading schematics from data/schematics into data/data.h5\n",
      "Processing generator type: simple_cubes\n",
      "Split data into 65 training samples, 21 validation samples, and 14 test samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating set: train for generator: simple_cubes: 100%|██████████| 65/65 [00:00<?, ?it/s]\n",
      "Updating set: validation for generator: simple_cubes: 100%|██████████| 21/21 [00:00<?, ?it/s]\n",
      "Updating set: test for generator: simple_cubes: 100%|██████████| 14/14 [00:00<00:00, 28163.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished updating HDF5 file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data_preparer import load_schematics\n",
    "\n",
    "schematics_dir = 'data/schematics'\n",
    "hdf5_path = 'data/data.h5'\n",
    "load_schematics(schematics_dir, hdf5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "from schempy import Schematic\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Assuming this is the function you want to apply to each sample name\n",
    "def process_sample_name(generator_type: str, sample_name: str) -> str:\n",
    "    schematic_path = f\"data/schematics/{generator_type}/{sample_name}.schem\"\n",
    "    schematic = Schematic.from_file(Path(schematic_path))\n",
    "    return schematic.name\n",
    "\n",
    "# Function to add a new dataset to each sample group\n",
    "def add_dataset_to_samples(hdf5_path: str) -> None:\n",
    "    with h5py.File(hdf5_path, 'a') as hdf5_file:\n",
    "        # Iterate over splits (val, train, test)\n",
    "        for split in hdf5_file.keys():\n",
    "            # Iterate over generator types within each split\n",
    "            for generator_type in hdf5_file[split].keys():\n",
    "                # Iterate over samples within each generator type\n",
    "                sample_names = hdf5_file[split][generator_type].keys()\n",
    "                sample_names_bar = tqdm(sample_names, desc=f\"Processing samples in split '{split}' and generator type '{generator_type}'\")\n",
    "                for sample_name in sample_names_bar:\n",
    "                    sample_group = hdf5_file[split][generator_type][sample_name]\n",
    "                    # Apply the function to the sample name\n",
    "                    description = process_sample_name(generator_type, sample_name)\n",
    "                    # Create a new dataset with the result of the function\n",
    "                    sample_group.create_dataset('description', data=description)\n",
    "                    # print(f\"Added description '{description}' to sample '{sample_name}'\")\n",
    "\n",
    "# Replace 'your_hdf5_file.hdf5' with the path to your actual HDF5 file\n",
    "add_dataset_to_samples('data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: test\n",
      "  Generator Type: simple_cubes\n",
      "    Sample: db13a7e9b6e953251a5ec5fc6ffdcc944ba6b3612a63dc28b8e284a6e46a4c89\n",
      "      Properties: {\"Hash\": \"db13a7e9b6e953251a5ec5fc6ffdcc944ba6b3612a63dc28b8e284a6e46a4c89\", \"Properties\": {\"generator_type\": \"shape\", \"shape_type\": \"cube\", \"side_length\": 8, \"structure_block_types\": [\"minecraft:redstone_ore[lit=false]\"], \"background_block_types\": [\"minecraft:air\"], \"position_offset\": [0, 0, 0], \"random_seed\": 845450454, \"region_size\": [64, 64, 64]}}\n",
      "      Dataset: description\n",
      "        Value: b'A perfect solid cube with a side length of 8 blocks. It is composed of redstone ore. It is floating within an empty void.'\n",
      "      Dataset: features\n",
      "        Shape: (1536,)\n",
      "      Dataset: target\n",
      "        Shape: (64, 64, 64)\n",
      "    Total samples: 20\n",
      "  Total generator types: 1\n",
      "Split: train\n",
      "  Generator Type: simple_cubes\n",
      "    Sample: 0511dc34d993ae2becf1fab0dd6100337afc2681ccf8ce880188597598057211\n",
      "      Properties: {\"Hash\": \"0511dc34d993ae2becf1fab0dd6100337afc2681ccf8ce880188597598057211\", \"Properties\": {\"generator_type\": \"shape\", \"shape_type\": \"cube\", \"side_length\": 8, \"structure_block_types\": [\"minecraft:waxed_weathered_cut_copper\"], \"background_block_types\": [\"minecraft:air\"], \"position_offset\": [0, 0, 0], \"random_seed\": 2766960655, \"region_size\": [64, 64, 64]}}\n",
      "      Dataset: description\n",
      "        Value: b'A perfect solid cube with a side length of 8 blocks. It is composed of waxed weathered cut copper. It is floating within an empty void.'\n",
      "      Dataset: features\n",
      "        Shape: (1536,)\n",
      "      Dataset: target\n",
      "        Shape: (64, 64, 64)\n",
      "    Total samples: 67\n",
      "  Total generator types: 1\n",
      "Split: validation\n",
      "  Generator Type: simple_cubes\n",
      "    Sample: b571c242fc2180b92b6e80d49aa45b23b2b93a402ceefb8986190fc754216ec5\n",
      "      Properties: {\"Hash\": \"b571c242fc2180b92b6e80d49aa45b23b2b93a402ceefb8986190fc754216ec5\", \"Properties\": {\"generator_type\": \"shape\", \"shape_type\": \"cube\", \"side_length\": 8, \"structure_block_types\": [\"minecraft:brown_terracotta\"], \"background_block_types\": [\"minecraft:air\"], \"position_offset\": [0, 0, 0], \"random_seed\": 2661786875, \"region_size\": [64, 64, 64]}}\n",
      "      Dataset: description\n",
      "        Value: b'A perfect solid cube with a side length of 8 blocks. It is composed of brown terracotta. It is floating within an empty void.'\n",
      "      Dataset: features\n",
      "        Shape: (1536,)\n",
      "      Dataset: target\n",
      "        Shape: (64, 64, 64)\n",
      "    Total samples: 13\n",
      "  Total generator types: 1\n",
      "Total splits: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import h5py\n",
    "\n",
    "from common.file_paths import BASE_DIR\n",
    "\n",
    "with h5py.File(os.path.join(BASE_DIR, 'data.h5'), 'r') as hf:\n",
    "    # Iterate over dataset splits (train, val, test)\n",
    "    for split in hf:\n",
    "        print(f\"Split: {split}\")\n",
    "\n",
    "        group = hf[split]\n",
    "\n",
    "        # Iterate over generator types\n",
    "        for generator_type in group:\n",
    "            print(f\"  Generator Type: {generator_type}\")\n",
    "\n",
    "            # Get the first sample in the group\n",
    "            sample = list(group[generator_type].keys())[0]\n",
    "            print(f\"    Sample: {sample}\")\n",
    "\n",
    "            # Print properties attribute\n",
    "            print(f\"      Properties: {group[generator_type][sample].attrs['properties']}\")\n",
    "\n",
    "            # Iterate over individual datasets\n",
    "            for dataset in group[generator_type][sample]:\n",
    "                print(f\"      Dataset: {dataset}\")\n",
    "\n",
    "                # Print the shape of the dataset if it is not a scalar\n",
    "                if group[generator_type][sample][dataset].shape != ():\n",
    "                    print(f\"        Shape: {group[generator_type][sample][dataset].shape}\")\n",
    "                else:\n",
    "                    print(f\"        Value: {group[generator_type][sample][dataset][()]}\")\n",
    "            \n",
    "            # Print the total number of samples in the group\n",
    "            print(f\"    Total samples: {len(group[generator_type].keys())}\")\n",
    "\n",
    "        # Print the total number of generator types in the split\n",
    "        print(f\"  Total generator types: {len(group.keys())}\")\n",
    "    \n",
    "    # Print the total number of splits in the file\n",
    "    print(f\"Total splits: {len(hf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                        | Params | In sizes  | Out sizes           \n",
      "-----------------------------------------------------------------------------------------\n",
      "0 | model | MinecraftStructureGenerator | 415 M  | [1, 1536] | [1, 300, 64, 64, 64]\n",
      "-----------------------------------------------------------------------------------------\n",
      "415 M     Trainable params\n",
      "0         Non-trainable params\n",
      "415 M     Total params\n",
      "1,662.990 Total estimated model params size (MB)\n",
      "c:\\Users\\mmmfr\\Documents\\Repositories\\minecraft-schematic-generator\\.venv\\Lib\\site-packages\\torch\\jit\\_trace.py:1093: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 6685937 / 78643200 (8.5%)\n",
      "Greatest absolute difference: 9.834766387939453e-05 at index (0, 151, 38, 17, 38) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 6577.828178985095 at index (0, 0, 19, 63, 36) (up to 1e-05 allowed)\n",
      "  _check_trace(\n",
      "c:\\Users\\mmmfr\\Documents\\Repositories\\minecraft-schematic-generator\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219: 100%|██████████| 8/8 [00:08<00:00,  0.94it/s, v_num=148]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.profilers import SimpleProfiler\n",
    "\n",
    "from common.file_paths import BASE_DIR\n",
    "from model.model import MinecraftStructureGenerator\n",
    "from modules import (EmbeddingVisualizationCallback, GenerateSchematicCallback,\n",
    "                     LightningMinecraftStructureGenerator, MinecraftDataModule)\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "INPUT_EMBEDDING_SIZE = 1536\n",
    "OUTPUT_EMBEDDING_SIZE = 80\n",
    "NUM_CLASSES = 300\n",
    "\n",
    "model = MinecraftStructureGenerator(INPUT_EMBEDDING_SIZE, OUTPUT_EMBEDDING_SIZE, NUM_CLASSES)\n",
    "# lightning_model = LightningMinecraftStructureGenerator(model, learning_rate=1e-3)\n",
    "lightning_model = LightningMinecraftStructureGenerator.load_from_checkpoint(\n",
    "    checkpoint_path='lightning_logs/minecraft_structure_generator/version_148/checkpoints/epoch=218-step=1752.ckpt', model=model)\n",
    "\n",
    "hdf5_file = os.path.join(BASE_DIR, 'data.h5')\n",
    "data_module = MinecraftDataModule(\n",
    "    file_path=hdf5_file,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "    'lightning_logs', name='minecraft_structure_generator', log_graph=True)\n",
    "profiler = SimpleProfiler()\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    verbose=True,\n",
    "    save_last=True,\n",
    "    save_top_k=3,\n",
    "    mode='min',\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "generate_schematic_callback = GenerateSchematicCallback(\n",
    "    save_path='schematic_viewer/public/schematics/',\n",
    "    data_module=data_module,\n",
    "    generate_train=True,\n",
    "    generate_val=False,\n",
    "    generate_every_n_epochs=5\n",
    ")\n",
    "embedding_visualization_callback = EmbeddingVisualizationCallback(\n",
    "    data_module=data_module,\n",
    "    frequency=10\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5000,\n",
    "    logger=logger,\n",
    "    # profiler=profiler,\n",
    "    gradient_clip_val=1.0,\n",
    "    log_every_n_steps=2,\n",
    "    limit_val_batches=0.0,\n",
    "    callbacks=[\n",
    "        # checkpoint_callback,\n",
    "        # early_stop_callback,\n",
    "        # embedding_visualization_callback,\n",
    "        generate_schematic_callback\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainer.fit(lightning_model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "\n",
    "from common.file_paths import TRAINING_DATA_DIR\n",
    "from model.model import MinecraftStructureGenerator\n",
    "from converter.converter import RegionTensorConverter\n",
    "\n",
    "# Assuming the constants are defined as in the training script\n",
    "INPUT_EMBEDDING_SIZE = 1536\n",
    "NUM_CLASSES = 345\n",
    "OUTPUT_SIZE = [64, 64, 64]\n",
    "\n",
    "# Initialize the model\n",
    "model = MinecraftStructureGenerator(INPUT_EMBEDDING_SIZE, NUM_CLASSES, OUTPUT_SIZE)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the directory where checkpoints are saved\n",
    "experiment_name = 'test14'\n",
    "checkpoint_dir = f'checkpoints/{experiment_name}'\n",
    "\n",
    "# List all checkpoint files\n",
    "checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_') and f.endswith('.pth')]\n",
    "\n",
    "# Extract epochs from file names and sort them\n",
    "epochs = [int(re.search(r'checkpoint_(\\d+).pth', f).group(1)) for f in checkpoint_files]\n",
    "latest_epoch = max(epochs, default=0)  # Use default=0 to handle the case when the list is empty\n",
    "\n",
    "# Load the trained model weights\n",
    "latest_checkpoint_file = f'checkpoint_{latest_epoch}.pth'\n",
    "print(f\"Loading checkpoint '{latest_checkpoint_file}'...\")\n",
    "checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint_file)\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "converter = RegionTensorConverter()\n",
    "\n",
    "# Loop to take user input and perform inference\n",
    "while True:\n",
    "    user_input = input(\"Enter your text input (or type 'exit' to stop): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    print(f\"Input: {user_input}\")\n",
    "\n",
    "    # Get the embedding\n",
    "    print(\"Getting embedding...\")\n",
    "    client = OpenAI()\n",
    "    embedding = client.embeddings.create(input=user_input, model=\"text-embedding-ada-002\").data[0].embedding\n",
    "    input_tensor = torch.tensor(embedding).unsqueeze(0)  # Add batch dimension\n",
    "    input_tensor = input_tensor.float()\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    print(f\"Embedding: {input_tensor.shape}\")\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        print(\"Performing inference...\")\n",
    "        output = model(input_tensor)\n",
    "        print(f\"Output: {output.shape}\")\n",
    "\n",
    "    # Process result\n",
    "    predicted_tokens = torch.argmax(output, dim=1)\n",
    "    predicted_tokens = predicted_tokens.squeeze(0)\n",
    "    print(f\"Predicted Tokens: {predicted_tokens.shape}\")\n",
    "\n",
    "    # Convert the output tensor to a schematic\n",
    "    print(\"Converting output tensor to schematic...\")\n",
    "    region = converter.tensor_to_region(predicted_tokens)\n",
    "    print(\"Conversion complete.\")\n",
    "\n",
    "    # Save the schematic to a file\n",
    "    print(\"Saving schematic to file...\")\n",
    "    # try:\n",
    "    #     schematic = region.as_schematic()\n",
    "    #     schematic.save('test.litematic')\n",
    "    # except:\n",
    "    #     print(\"Failed to save litematica schematic to file.\")\n",
    "    # try:\n",
    "    #     structure_nbt = region.to_structure_nbt()\n",
    "    #     structure_nbt.save('test.nbt')\n",
    "    # except:\n",
    "    #     print(\"Failed to save NBT schematic to file.\")\n",
    "    sponge_nbt = region.to_sponge_nbt()\n",
    "    sponge_nbt.save(f'{user_input.lower().replace(\" \", \"\")}.schem')\n",
    "    print(\"Schematic saved to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Compound({'Date': Long(1700278591692), 'WorldEdit': Compound({'Version': String('(unknown)'), 'EditingPlatform': String('enginehub:fabric'), 'Origin': IntArray([Int(0), Int(0), Int(0)]), 'Platforms': Compound({'enginehub:fabric': Compound({'Name': String('Fabric-Official'), 'Version': String('7.3.0-beta-02+e11f161')})})})})\n",
      "minecraft:air\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from schempy.schematic import Block, Schematic, BlockEntity\n",
    "\n",
    "schematic = Schematic.from_file(Path('sponge.3.schem'))\n",
    "print(schematic.metadata)\n",
    "\n",
    "# Usage example\n",
    "# schematic = Schematic(width=10, height=10, length=10)\n",
    "schematic.metadata['Description'] = \"This is a schematic generated by SchemPy\"\n",
    "\n",
    "# Set a block at coordinates (x=1, y=2, z=3) to a specific value, e.g., 42\n",
    "block = Block(\"minecraft:andesite\")\n",
    "schematic.set_block(1, 2, 3, block)\n",
    "block = Block(\"minecraft:oak_planks\")\n",
    "schematic.set_block(0, 0, 0, block)\n",
    "\n",
    "# Retrieve the block value at coordinates (x=1, y=2, z=3)\n",
    "block = schematic.get_block(8, 9, 0)\n",
    "print(block)\n",
    "block_entity = BlockEntity(\"minecraft:chest\", 0, 0, 0, {\"LootTable\": \"minecraft:chests/simple_dungeon\"})\n",
    "schematic.add_block_entity(block_entity)\n",
    "\n",
    "schematic.save_to_file(Path('example.schem'), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
