{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples: 100%|██████████| 420/420 [00:00<00:00, 19085.05it/s]\n",
      "Generating samples: 100%|██████████| 450/450 [00:00<00:00, 18740.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from common import constants\n",
    "from schematic_generator import generator\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "configs = [\n",
    "    # Simple shapes\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"sphere\"],\n",
    "        \"radius\": [lambda: random.randint(1, (constants.region_size[0] // 2) - 1)] * 5,\n",
    "        \"structure_block_types\": [[block] for block in constants.simple_block_types] + [lambda: random.sample(constants.simple_block_types, 3)] * len(constants.simple_block_types),\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [lambda: (random.randint(-100, 100), random.randint(-100, 100), random.randint(-100, 100))],\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    },\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"cube\"],\n",
    "        \"side_length\": [lambda: random.randint(1, constants.region_size[0] - 1)] * 5,\n",
    "        \"structure_block_types\": [[block] for block in constants.simple_block_types] + [lambda: random.sample(constants.simple_block_types, 3)] * len(constants.simple_block_types),\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [lambda: (random.randint(-100, 100), random.randint(-100, 100), random.randint(-100, 100))],\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    },\n",
    "    # Filled\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"sphere\"],\n",
    "        \"radius\": [lambda: random.randint(3, (constants.region_size[0] // 2) - 1)] * 3,\n",
    "        \"structure_block_types\": [[block] for block in constants.simple_block_types] + [lambda: random.sample(constants.simple_block_types, 3)] * (len(constants.simple_block_types) // 3),\n",
    "        \"structure_fill_block_types\": [[\"minecraft:air\"], lambda: random.sample(constants.simple_block_types, 1), lambda: random.sample(constants.simple_block_types, 3)],\n",
    "        \"thickness\": [lambda: random.randint(1, 3)],\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [lambda: (random.randint(-100, 100), random.randint(-100, 100), random.randint(-100, 100))],\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    },\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"cube\"],\n",
    "        \"side_length\": [lambda: random.randint(7, constants.region_size[0] - 1)] * 3,\n",
    "        \"structure_block_types\": [[block] for block in constants.simple_block_types] + [lambda: random.sample(constants.simple_block_types, 3)] * (len(constants.simple_block_types) // 3),\n",
    "        \"structure_fill_block_types\": [[\"minecraft:air\"], lambda: random.sample(constants.simple_block_types, 1), lambda: random.sample(constants.simple_block_types, 3)],\n",
    "        \"thickness\": [lambda: random.randint(1, 3)],\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [lambda: (random.randint(-100, 100), random.randint(-100, 100), random.randint(-100, 100))],\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    }\n",
    "]\n",
    "\n",
    "simple_cubes = [\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"cube\"],\n",
    "        \"side_length\": [1, 2, 3, 4, 6, 7, 8],\n",
    "        \"structure_block_types\": [[block] for block in random.sample(constants.simple_block_types, 12)],\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [lambda: (random.randint(-100, 100), random.randint(-100, 100), random.randint(-100, 100))] * 5,\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    }\n",
    "]\n",
    "\n",
    "simple_spheres = [\n",
    "    {\n",
    "        \"generator_type\": [\"shape\"],\n",
    "        \"shape_type\": [\"sphere\"],\n",
    "        \"radius\": [1, 2, 3],\n",
    "        \"structure_block_types\": [[block] for block in random.sample(constants.simple_block_types, 30)],\n",
    "        \"background_block_types\": [[\"minecraft:air\"]],\n",
    "        \"position_offset\": [lambda: (random.randint(-100, 100), random.randint(-100, 100), random.randint(-100, 100))] * 5,\n",
    "        \"random_seed\": [lambda: random.randint(0, 2**32 - 1)],\n",
    "        \"region_size\": [constants.region_size]\n",
    "    }\n",
    "]\n",
    "\n",
    "# generator.generate_samples_from_configurations(configs, dry_run=False)\n",
    "generator.generate_samples_from_configurations(simple_cubes, 'simple_cubes')\n",
    "generator.generate_samples_from_configurations(simple_spheres, 'simple_spheres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading schematics from data/schematics into data/data.h5\n",
      "Processing generator type: simple_cubes\n",
      "Split data into 289 training samples, 64 validation samples, and 67 test samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating set: train for generator: simple_cubes: 100%|██████████| 289/289 [00:00<?, ?it/s]\n",
      "Updating set: validation for generator: simple_cubes: 100%|██████████| 64/64 [00:00<00:00, 128253.92it/s]\n",
      "Updating set: test for generator: simple_cubes: 100%|██████████| 67/67 [00:00<00:00, 133945.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing generator type: simple_spheres\n",
      "Split data into 305 training samples, 64 validation samples, and 81 test samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating set: train for generator: simple_spheres: 100%|██████████| 305/305 [00:00<?, ?it/s]\n",
      "Updating set: validation for generator: simple_spheres: 100%|██████████| 64/64 [00:00<?, ?it/s]\n",
      "Updating set: test for generator: simple_spheres: 100%|██████████| 81/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished updating HDF5 file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data_preparer import load_schematics\n",
    "\n",
    "schematics_dir = 'data/schematics'\n",
    "hdf5_path = 'data/data.h5'\n",
    "load_schematics(schematics_dir, hdf5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "from schempy import Schematic\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Assuming this is the function you want to apply to each sample name\n",
    "def process_sample_name(generator_type: str, sample_name: str) -> str:\n",
    "    schematic_path = f\"data/schematics/{generator_type}/{sample_name}.schem\"\n",
    "    schematic = Schematic.from_file(Path(schematic_path))\n",
    "    return schematic.name\n",
    "\n",
    "# Function to add a new dataset to each sample group\n",
    "def add_dataset_to_samples(hdf5_path: str) -> None:\n",
    "    with h5py.File(hdf5_path, 'a') as hdf5_file:\n",
    "        # Iterate over splits (val, train, test)\n",
    "        for split in hdf5_file.keys():\n",
    "            # Iterate over generator types within each split\n",
    "            for generator_type in hdf5_file[split].keys():\n",
    "                # Iterate over samples within each generator type\n",
    "                sample_names = hdf5_file[split][generator_type].keys()\n",
    "                sample_names_bar = tqdm(sample_names, desc=f\"Processing samples in split '{split}' and generator type '{generator_type}'\")\n",
    "                for sample_name in sample_names_bar:\n",
    "                    sample_group = hdf5_file[split][generator_type][sample_name]\n",
    "                    # Apply the function to the sample name\n",
    "                    description = process_sample_name(generator_type, sample_name)\n",
    "                    # Create a new dataset with the result of the function\n",
    "                    sample_group.create_dataset('description', data=description)\n",
    "                    # print(f\"Added description '{description}' to sample '{sample_name}'\")\n",
    "\n",
    "# Replace 'your_hdf5_file.hdf5' with the path to your actual HDF5 file\n",
    "add_dataset_to_samples('data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: test\n",
      "  Generator Type: simple_cubes\n",
      "    Sample: ddd06043d254ba45b645ab627bfe55ab20a7c6cd572f101a9f7bc2cc1349fc4b\n",
      "      Properties: {\"Hash\": \"ddd06043d254ba45b645ab627bfe55ab20a7c6cd572f101a9f7bc2cc1349fc4b\", \"Properties\": {\"generator_type\": \"shape\", \"shape_type\": \"cube\", \"side_length\": 8, \"structure_block_types\": [\"minecraft:oak_planks\"], \"background_block_types\": [\"minecraft:air\"], \"position_offset\": [-65, -91, 29], \"random_seed\": 2496062452, \"region_size\": [16, 16, 16]}}\n",
      "      Dataset: description\n",
      "        Value: b'A perfect solid cube with a side length of 8 blocks. It is composed of oak planks. It is floating within an empty void.'\n",
      "      Dataset: features\n",
      "        Shape: (1536,)\n",
      "      Dataset: target\n",
      "        Shape: (16, 16, 16)\n",
      "    Total samples: 17\n",
      "  Total generator types: 1\n",
      "Split: train\n",
      "  Generator Type: simple_cubes\n",
      "    Sample: 03033caa8958c87b10524cba5f7dee8a3d4948337d87e5fee6a0e756f655faa0\n",
      "      Properties: {\"Hash\": \"03033caa8958c87b10524cba5f7dee8a3d4948337d87e5fee6a0e756f655faa0\", \"Properties\": {\"generator_type\": \"shape\", \"shape_type\": \"cube\", \"side_length\": 8, \"structure_block_types\": [\"minecraft:stone_bricks\"], \"background_block_types\": [\"minecraft:air\"], \"position_offset\": [6, -44, 54], \"random_seed\": 3607213216, \"region_size\": [16, 16, 16]}}\n",
      "      Dataset: description\n",
      "        Value: b'A perfect solid cube with a side length of 8 blocks. It is composed of stone bricks. It is floating within an empty void.'\n",
      "      Dataset: features\n",
      "        Shape: (1536,)\n",
      "      Dataset: target\n",
      "        Shape: (16, 16, 16)\n",
      "    Total samples: 63\n",
      "  Total generator types: 1\n",
      "Split: validation\n",
      "  Generator Type: simple_cubes\n",
      "    Sample: b37487e6e7742149f47a2225092ce1b8778d8a26e2dbd145314ddbb4d8a9ae3c\n",
      "      Properties: {\"Hash\": \"b37487e6e7742149f47a2225092ce1b8778d8a26e2dbd145314ddbb4d8a9ae3c\", \"Properties\": {\"generator_type\": \"shape\", \"shape_type\": \"cube\", \"side_length\": 8, \"structure_block_types\": [\"minecraft:stone_bricks\"], \"background_block_types\": [\"minecraft:air\"], \"position_offset\": [78, -48, 94], \"random_seed\": 3918321625, \"region_size\": [16, 16, 16]}}\n",
      "      Dataset: description\n",
      "        Value: b'A perfect solid cube with a side length of 8 blocks. It is composed of stone bricks. It is floating within an empty void.'\n",
      "      Dataset: features\n",
      "        Shape: (1536,)\n",
      "      Dataset: target\n",
      "        Shape: (16, 16, 16)\n",
      "    Total samples: 20\n",
      "  Total generator types: 1\n",
      "Total splits: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import h5py\n",
    "\n",
    "from common.file_paths import BASE_DIR\n",
    "\n",
    "with h5py.File(os.path.join(BASE_DIR, 'data.h5'), 'r') as hf:\n",
    "    # Iterate over dataset splits (train, val, test)\n",
    "    for split in hf:\n",
    "        print(f\"Split: {split}\")\n",
    "\n",
    "        group = hf[split]\n",
    "\n",
    "        # Iterate over generator types\n",
    "        for generator_type in group:\n",
    "            print(f\"  Generator Type: {generator_type}\")\n",
    "\n",
    "            # Get the first sample in the group\n",
    "            sample = list(group[generator_type].keys())[0]\n",
    "            print(f\"    Sample: {sample}\")\n",
    "\n",
    "            # Print properties attribute\n",
    "            print(f\"      Properties: {group[generator_type][sample].attrs['properties']}\")\n",
    "\n",
    "            # Iterate over individual datasets\n",
    "            for dataset in group[generator_type][sample]:\n",
    "                print(f\"      Dataset: {dataset}\")\n",
    "\n",
    "                # Print the shape of the dataset if it is not a scalar\n",
    "                if group[generator_type][sample][dataset].shape != ():\n",
    "                    print(f\"        Shape: {group[generator_type][sample][dataset].shape}\")\n",
    "                else:\n",
    "                    print(f\"        Value: {group[generator_type][sample][dataset][()]}\")\n",
    "            \n",
    "            # Print the total number of samples in the group\n",
    "            print(f\"    Total samples: {len(group[generator_type].keys())}\")\n",
    "\n",
    "        # Print the total number of generator types in the split\n",
    "        print(f\"  Total generator types: {len(group.keys())}\")\n",
    "    \n",
    "    # Print the total number of splits in the file\n",
    "    print(f\"Total splits: {len(hf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "\n",
    "from common.file_paths import TRAINING_DATA_DIR\n",
    "from model.model import MinecraftStructureGenerator\n",
    "from converter.converter import RegionTensorConverter\n",
    "\n",
    "# Initialize the model\n",
    "model = TransformerMinecraftStructureGenerator(INPUT_EMBEDDING_SIZE, NUM_CLASSES, OUTPUT_SIZE)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the directory where checkpoints are saved\n",
    "experiment_name = 'test14'\n",
    "checkpoint_dir = f'checkpoints/{experiment_name}'\n",
    "\n",
    "# List all checkpoint files\n",
    "checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_') and f.endswith('.pth')]\n",
    "\n",
    "# Extract epochs from file names and sort them\n",
    "epochs = [int(re.search(r'checkpoint_(\\d+).pth', f).group(1)) for f in checkpoint_files]\n",
    "latest_epoch = max(epochs, default=0)  # Use default=0 to handle the case when the list is empty\n",
    "\n",
    "# Load the trained model weights\n",
    "latest_checkpoint_file = f'checkpoint_{latest_epoch}.pth'\n",
    "print(f\"Loading checkpoint '{latest_checkpoint_file}'...\")\n",
    "checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint_file)\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "converter = RegionTensorConverter()\n",
    "\n",
    "# Loop to take user input and perform inference\n",
    "while True:\n",
    "    user_input = input(\"Enter your text input (or type 'exit' to stop): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    print(f\"Input: {user_input}\")\n",
    "\n",
    "    # Get the embedding\n",
    "    print(\"Getting embedding...\")\n",
    "    client = OpenAI()\n",
    "    embedding = client.embeddings.create(input=user_input, model=\"text-embedding-ada-002\").data[0].embedding\n",
    "    input_tensor = torch.tensor(embedding).unsqueeze(0)  # Add batch dimension\n",
    "    input_tensor = input_tensor.float()\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    print(f\"Embedding: {input_tensor.shape}\")\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        print(\"Performing inference...\")\n",
    "        output = model(input_tensor)\n",
    "        print(f\"Output: {output.shape}\")\n",
    "\n",
    "    # Process result\n",
    "    predicted_tokens = torch.argmax(output, dim=1)\n",
    "    predicted_tokens = predicted_tokens.squeeze(0)\n",
    "    print(f\"Predicted Tokens: {predicted_tokens.shape}\")\n",
    "\n",
    "    # Convert the output tensor to a schematic\n",
    "    print(\"Converting output tensor to schematic...\")\n",
    "    region = converter.tensor_to_region(predicted_tokens)\n",
    "    print(\"Conversion complete.\")\n",
    "\n",
    "    # Save the schematic to a file\n",
    "    print(\"Saving schematic to file...\")\n",
    "    # try:\n",
    "    #     schematic = region.as_schematic()\n",
    "    #     schematic.save('test.litematic')\n",
    "    # except:\n",
    "    #     print(\"Failed to save litematica schematic to file.\")\n",
    "    # try:\n",
    "    #     structure_nbt = region.to_structure_nbt()\n",
    "    #     structure_nbt.save('test.nbt')\n",
    "    # except:\n",
    "    #     print(\"Failed to save NBT schematic to file.\")\n",
    "    sponge_nbt = region.to_sponge_nbt()\n",
    "    sponge_nbt.save(f'{user_input.lower().replace(\" \", \"\")}.schem')\n",
    "    print(\"Schematic saved to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Compound({'Date': Long(1700278591692), 'WorldEdit': Compound({'Version': String('(unknown)'), 'EditingPlatform': String('enginehub:fabric'), 'Origin': IntArray([Int(0), Int(0), Int(0)]), 'Platforms': Compound({'enginehub:fabric': Compound({'Name': String('Fabric-Official'), 'Version': String('7.3.0-beta-02+e11f161')})})})})\n",
      "minecraft:air\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from schempy.schematic import Block, Schematic, BlockEntity\n",
    "\n",
    "schematic = Schematic.from_file(Path('sponge.3.schem'))\n",
    "print(schematic.metadata)\n",
    "\n",
    "# Usage example\n",
    "# schematic = Schematic(width=10, height=10, length=10)\n",
    "schematic.metadata['Description'] = \"This is a schematic generated by SchemPy\"\n",
    "\n",
    "# Set a block at coordinates (x=1, y=2, z=3) to a specific value, e.g., 42\n",
    "block = Block(\"minecraft:andesite\")\n",
    "schematic.set_block(1, 2, 3, block)\n",
    "block = Block(\"minecraft:oak_planks\")\n",
    "schematic.set_block(0, 0, 0, block)\n",
    "\n",
    "# Retrieve the block value at coordinates (x=1, y=2, z=3)\n",
    "block = schematic.get_block(8, 9, 0)\n",
    "print(block)\n",
    "block_entity = BlockEntity(\"minecraft:chest\", 0, 0, 0, {\"LootTable\": \"minecraft:chests/simple_dungeon\"})\n",
    "schematic.add_block_entity(block_entity)\n",
    "\n",
    "schematic.save_to_file(Path('example.schem'), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
